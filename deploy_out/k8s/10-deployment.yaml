apiVersion: apps/v1
kind: Deployment
metadata:
  name: llmserve
  namespace: llmserve
  labels:
    app.kubernetes.io/name: llmserve
    app.kubernetes.io/component: api
spec:
  replicas: 8
  revisionHistoryLimit: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: llmserve
      app.kubernetes.io/component: api
  template:
    metadata:
      labels:
        app.kubernetes.io/name: llmserve
        app.kubernetes.io/component: api
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9400"
        prometheus.io/path: "/metrics"
    spec:
      # Uncomment on clusters with GPU runtime class
      # runtimeClassName: nvidia
      # Tolerate GPU nodes if tainted
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: llmserve
          image: ghcr.io/yourorg/llmserve:0.1.0
          imagePullPolicy: IfNotPresent
          args: ["llmserve","up","-f","/app/llmserve.yaml"]
          ports:
            - name: http
              containerPort: 8000
            - name: metrics
              containerPort: 9400
          env:
            # Optional: pin NCCL/UCX for multi-node performance (adjust to your fabric)
            - name: NCCL_DEBUG
              value: "WARN"
            - name: NCCL_P2P_LEVEL
              value: "SYS"
            - name: NCCL_SOCKET_IFNAME
              value: "eth0"
            - name: UCX_TLS
              value: "rc,ud,mm,self"
            - name: UCX_NET_DEVICES
              value: "eth0"
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "compute,utility"
          volumeMounts:
            - name: cfg
              mountPath: /app/llmserve.yaml
              subPath: llmserve.yaml
            - name: kvpages
              mountPath: /var/lib/kvpages
          resources:
            requests:
              cpu: "2000m"
              memory: "12Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4000m"
              memory: "24Gi"
              nvidia.com/gpu: "1"
          readinessProbe:
            httpGet:
              path: /healthz
              port: http
            initialDelaySeconds: 10
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /healthz
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: cfg
          configMap:
            name: llmserve-manifest
        - name: kvpages
          persistentVolumeClaim:
            claimName: kvpages-pvc
      nodeSelector:
        kubernetes.io/arch: amd64
