[project]
name = "llmserve"
version = "0.1.0"
description = "Production-ready LLM serving with vLLM, disaggregated prefill/decode, continuous batching, tiered KV-cache (GPU → DRAM → NVMe → Object), NIXL/UCX/NCCL transfer engines, speculative decoding, and a fair-share scheduler. Single command brings the whole stack up from a YAML manifest."
authors = [
    {name = "pritaman",email = "nayak264@gmail.com"}
]
license = {text = "MIT License"}
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
  "typer>=0.12",
  "rich>=13.7",
  "pyyaml>=6.0",
  "pydantic>=2.7",
  "fastapi>=0.111",
  "uvicorn[standard]>=0.30",
  "prometheus-client>=0.20",
  # add more as we wire engines (vllm, transformers, etc.)
  "orjson>=3.10",
  "vllm>=0.10",
]


[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[project.scripts]
llmserve = "llmserve.cli:app"
